# ===================================================================
#           CRAFT (Chemical Representation and Analysis)
#                 Main Experiment Configuration File (v0.9.4)
# ===================================================================
#
# Instructions:
# 1. Modify "experiment_name" and "task_type" to suit your experiment.
# 2. In the "data" section, choose one of the four "source_mode" options and fill in its configuration.
#    Ensure only one mode's configuration is active; others can be commented out.
# 3. In the "features" section, configure the molecular features to be generated and whether to apply scaling.
# 4. In the "split_mode" and "split_config" sections, define your data splitting strategy.
#    (Note: This section is only effective when data.source_mode is 'single_file' or 'features_only').
# 5. In the "training" section, select the models to run and the number of HPO trials.
#
# ===================================================================


# --- 1. Basic Experiment Settings ---
experiment_name: "Prediction_Demo_EN" # Name of the experiment, used for creating the output folder.
task_type: "regression"               # "regression", "binary_classification", or "multiclass_classification"

# --- 2. Data Source Configuration ---
data:
  # Select one data source mode:
  # - "single_file":       Provide one file with SMILES, to be split by the program.
  # - "pre_split_t_v_t":   Provide pre-split train/validation/test sets with SMILES.
  # - "pre_split_cv":      Provide pre-split train/test sets with SMILES for cross-validation.
  # - "features_only":     Provide a file with features and targets, no SMILES.
  # Note: Only one mode can be active. The feature generation section will be ignored for "features_only".
  
  source_mode: "single_file" # <--- Choose your mode here

  # --- Mode 1: single_file ---
  single_file_config:
    main_file_path: "data/demo_dataset.csv" # Main data file containing SMILES and target values.
    smiles_col: "SMILES"                    # Name of the SMILES column.
    target_col: "RT"                        # Name of the target column (e.g., Yield, energy, Activity).
    precomputed_features:
      path: null                            # Set to null to use main_file_path.
      # Specify feature columns: "start:end" (exclusive of end), "start:", ":end", or a list of column names.
      feature_columns: null                 # Example: "8:10" for columns 8 and 9. Set to null if none.

  # --- Mode 2: pre_split_t_v_t ---
  # pre_split_t_v_t_config:
  #   train_path: "data/user_split/train.csv"
  #   valid_path: "data/user_split/valid.csv"
  #   test_path: "data/user_split/test.csv"
  #   smiles_col: "SMILES"
  #   target_col: "TARGET"
  #   precomputed_features:
  #     feature_columns: null

  # --- Mode 3: pre_split_cv ---
  # pre_split_cv_config:
  #   train_path: "data/user_split/train_for_cv.csv"
  #   test_path: "data/user_split/test_for_cv.csv"
  #   smiles_col: "SMILES"
  #   target_col: "TARGET"
  #   precomputed_features:
  #     feature_columns: null

  # --- Mode 4: features_only ---
  # features_only_config:
  #   file_path: "data/features_and_target.csv"
  #   target_col: "activity"
  #   feature_columns: "1:1001" # e.g., features are in columns 1 through 1000

# --- 3. Dynamic Feature Generation (Ignored in 'features_only' mode) ---
features:
  # List of features to generate. Set to [] if none.
  # Available types: "maccs", "morgan", "rdkit", "atompair", "torsion", "rdkit_descriptors",
  # 'chemberta', 'molt5', 'chemroberta', 'unimol'.
  # Note: Pre-trained models like 'unimol' will be downloaded on first use (can be up to 6GB).
  generators:
    - type: "morgan"
      nBits: 1024
      radius: 2
    - type: "rdkit_descriptors"
    - type: "unimol"
      model_version: "v2"
      model_size: "84m"
      
  # Whether to apply StandardScaler to the final feature matrix.
  scaling: true

# --- 4. Data Splitting & Validation Strategy (Only for 'single_file' or 'features_only' mode) ---
# Choose a mode: "train_valid_test" or "cross_validation"
# Use "train_valid_test" for large datasets, "cross_validation" for smaller ones.
split_mode: "train_valid_test"

split_config:
  # Config for "train_valid_test" mode
  train_valid_test:
    train_size: 0.8
    valid_size: 0.1
    test_size: 0.1
    random_state: 0

  # Config for "cross_validation" mode
  cross_validation:
    n_splits: 5           # Number of folds for CV.
    test_size_for_cv: 0.2 # Hold-out test set size.
    random_state: 42

# --- 5. Model Training Configuration ---
training:
  # List of models to run.
  # Available: xgb, lgbm, rf, cat, hgb, dt, knn, svr, ridge, ann, adab, lr, svc, krr
  models_to_run:
    - "xgb"
    # - "lgbm"
    # - "rf"
    # - "ann"
  
  # Number of trials for Optuna hyperparameter optimization.
  # Use fewer trials for large datasets, more for smaller ones.
  n_trials: 50
  
  # HPO Strategy:
  # - If split_mode is cross_validation, HPO uses CV.
  # - If split_mode is train_valid_test, HPO uses the validation set.
  
  # (Optional) Reduce Optuna's logging verbosity.
  quiet_optuna: true