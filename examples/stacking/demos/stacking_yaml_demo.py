#!/usr/bin/env python3
"""
CRAFT æ¨¡å‹å †å  YAML é…ç½®æ¼”ç¤º

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶æ¥è¿›è¡Œæ¨¡å‹å †å ã€‚
æ”¯æŒä»é…ç½®æ–‡ä»¶è‡ªåŠ¨åŠ è½½æ¨¡å‹ã€è®¾ç½®å †å æ–¹æ³•ã€è®­ç»ƒå…ƒæ¨¡å‹ç­‰åŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•:
    python stacking_yaml_demo.py --config config_stacking.yaml

éœ€è¦å…ˆæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨æŒ‡å®šçš„å®éªŒç›®å½•ä¸­ã€‚
"""

import argparse
import os
import sys
import yaml
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from model_stacking import ModelStacker, load_stacking_config_from_yaml

def load_yaml_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"âŒ YAMLæ–‡ä»¶è§£æé”™è¯¯: {e}")
        sys.exit(1)

def save_results(results: Dict[str, Any], config: Dict[str, Any]):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    save_config = config.get('save', {})
    results_dir = save_config.get('results_dir', 'output/stacking_results')
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(results_dir, exist_ok=True)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    if save_config.get('save_evaluation', True) and 'evaluation' in results:
        eval_file = os.path.join(results_dir, 'evaluation_results.yaml')
        with open(eval_file, 'w', encoding='utf-8') as f:
            yaml.dump(results['evaluation'], f, default_flow_style=False, allow_unicode=True)
        print(f"âœ“ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {eval_file}")
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    if save_config.get('save_predictions', True) and 'predictions' in results:
        pred_file = os.path.join(results_dir, 'predictions.csv')
        predictions_df = pd.DataFrame(results['predictions'])
        predictions_df.to_csv(pred_file, index=False)
        print(f"âœ“ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {pred_file}")
    
    # ä¿å­˜é…ç½®æ–‡ä»¶å‰¯æœ¬
    if save_config.get('save_config_copy', True):
        config_copy = os.path.join(results_dir, 'stacking_config.yaml')
        with open(config_copy, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        print(f"âœ“ é…ç½®æ–‡ä»¶å‰¯æœ¬å·²ä¿å­˜åˆ°: {config_copy}")

def run_stacking_from_yaml(config_path: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶è¿è¡Œæ¨¡å‹å †å 
    
    Args:
        config_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: è¿è¡Œç»“æœ
    """
    print("ğŸš€ å¼€å§‹YAMLé…ç½®æ¨¡å‹å †å ")
    print("=" * 60)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    config = load_yaml_config(config_path)
    
    # ä»YAMLé…ç½®åˆ›å»ºå †å å™¨
    print("\nğŸ”§ åˆ›å»ºæ¨¡å‹å †å å™¨...")
    try:
        stacker = load_stacking_config_from_yaml(config_path)
    except Exception as e:
        print(f"âŒ åˆ›å»ºå †å å™¨å¤±è´¥: {e}")
        return {'success': False, 'error': str(e)}
    
    results = {'success': True, 'config_path': config_path}
    
    # è‡ªåŠ¨è¯„ä¼°ï¼ˆå¦‚æœé…ç½®ï¼‰
    eval_config = config.get('evaluation', {})
    if eval_config.get('auto_evaluate', True):
        print("\nğŸ“Š å¼€å§‹è‡ªåŠ¨è¯„ä¼°...")
        try:
            use_test_set = eval_config.get('use_test_set', True)
            evaluation = stacker.evaluate(auto_load=True, use_test_set=use_test_set)
            results['evaluation'] = evaluation
            
            print("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
            print("-" * 40)
            
            # æ˜¾ç¤ºä¸»è¦æŒ‡æ ‡
            if stacker.task_type == 'regression':
                if 'r2' in evaluation:
                    print(f"  RÂ² Score: {evaluation['r2']:.4f}")
                if 'rmse' in evaluation:
                    print(f"  RMSE: {evaluation['rmse']:.4f}")
                if 'mae' in evaluation:
                    print(f"  MAE: {evaluation['mae']:.4f}")
            else:
                if 'accuracy' in evaluation:
                    print(f"  Accuracy: {evaluation['accuracy']:.4f}")
                if 'log_loss' in evaluation:
                    print(f"  Log Loss: {evaluation['log_loss']:.4f}")
            
            # æ˜¾ç¤ºåŸºç¡€æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ
            if eval_config.get('compare_with_base', True) and 'base_model_performance' in evaluation:
                print("\nğŸ” åŸºç¡€æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:")
                print("-" * 40)
                base_perf = evaluation['base_model_performance']
                for model_name, metrics in base_perf.items():
                    if stacker.task_type == 'regression':
                        r2 = metrics.get('r2', 'N/A')
                        rmse = metrics.get('rmse', 'N/A')
                        print(f"  {model_name}: RÂ²={r2:.4f}, RMSE={rmse:.4f}")
                    else:
                        acc = metrics.get('accuracy', 'N/A')
                        print(f"  {model_name}: Accuracy={acc:.4f}")
            
        except Exception as e:
            print(f"âš ï¸  è¯„ä¼°å¤±è´¥: {e}")
            results['evaluation_error'] = str(e)
    
    # ä¿å­˜å †å å™¨ï¼ˆå¦‚æœé…ç½®ï¼‰
    save_config = config.get('save', {})
    if save_config.get('save_stacker', True):
        save_path = save_config.get('save_path', 'output/stacked_models/ensemble_model.pkl')
        print(f"\nğŸ’¾ ä¿å­˜å †å å™¨åˆ°: {save_path}")
        try:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            stacker.save(save_path)
            results['saved_model_path'] = save_path
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜å¤±è´¥: {e}")
            results['save_error'] = str(e)
    
    # ä¿å­˜ç»“æœ
    try:
        save_results(results, config)
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    print("\nâœ… æ¨¡å‹å †å å®Œæˆ!")
    return results

def create_sample_config(output_path: str = "config_stacking_example.yaml"):
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    sample_config = {
        'stacking': {
            'experiment_dir': 'output/my_experiment',
            'method': 'weighted_average',
            'models': [
                {'name': 'xgb', 'weight': 0.4, 'enabled': True},
                {'name': 'lgbm', 'weight': 0.3, 'enabled': True},
                {'name': 'catboost', 'weight': 0.3, 'enabled': True}
            ],
            'meta_model': {
                'auto_train': False,
                'validation': {
                    'auto_load': True,
                    'size': 100
                }
            }
        },
        'evaluation': {
            'auto_evaluate': True,
            'use_test_set': True,
            'compare_with_base': True
        },
        'save': {
            'save_stacker': True,
            'save_path': 'output/stacked_models/example_ensemble.pkl',
            'results_dir': 'output/stacking_results',
            'save_evaluation': True,
            'save_config_copy': True
        }
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(sample_config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"âœ“ ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: {output_path}")

def main():
    parser = argparse.ArgumentParser(
        description="CRAFT æ¨¡å‹å †å  YAML é…ç½®æ¼”ç¤º",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  python stacking_yaml_demo.py --config config_stacking.yaml
  
  # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
  python stacking_yaml_demo.py --create-sample-config
  
  # æŒ‡å®šè¾“å‡ºè·¯å¾„åˆ›å»ºç¤ºä¾‹é…ç½®
  python stacking_yaml_demo.py --create-sample-config --output my_config.yaml

æ³¨æ„äº‹é¡¹:
  1. ç¡®ä¿å®éªŒç›®å½•ä¸­æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
  2. é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åç§°å¿…é¡»ä¸å®é™…æ¨¡å‹æ–‡ä»¶åŒ¹é…
  3. ä½¿ç”¨å…ƒå­¦ä¹ å™¨æ—¶ä¼šè‡ªåŠ¨è®­ç»ƒï¼Œéœ€è¦éªŒè¯æ•°æ®
        """
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--create-sample-config',
        action='store_true',
        help='åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='config_stacking_example.yaml',
        help='ç¤ºä¾‹é…ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„ (é»˜è®¤: config_stacking_example.yaml)'
    )
    
    args = parser.parse_args()
    
    if args.create_sample_config:
        create_sample_config(args.output)
        return
    
    if not args.config:
        print("âŒ è¯·æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨ --create-sample-config åˆ›å»ºç¤ºä¾‹é…ç½®")
        parser.print_help()
        sys.exit(1)
    
    if not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        sys.exit(1)
    
    # è¿è¡Œæ¨¡å‹å †å 
    results = run_stacking_from_yaml(args.config)
    
    if results['success']:
        print(f"\nğŸ‰ æ¨¡å‹å †å æˆåŠŸå®Œæˆ!")
        if 'evaluation' in results:
            eval_result = results['evaluation']
            print(f"   å †å æ–¹æ³•: {eval_result.get('stacking_method', 'unknown')}")
            print(f"   æ¨¡å‹æ•°é‡: {eval_result.get('n_models', 'unknown')}")
    else:
        print(f"\nâŒ æ¨¡å‹å †å å¤±è´¥: {results.get('error', 'unknown error')}")
        sys.exit(1)

if __name__ == "__main__":
    main() 